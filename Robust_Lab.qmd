---
title: "Robust Methods Lab"
format: html
editor: visual
execute: 
  message: false
---

# Lab 1- Robust Methods

## Instructions

-   If you are fitting a model, display the model output in a neatly formatted table. (The `tidy` and `kable` functions can help!)

-   If you are creating a plot, use clear labels for all axes, titles, etc.

-   Commit and push your work to GitHub regularly, at least after each exercise. Write short and informative commit messages.

-   When you're done, we should be able to knit the final version of the QMD in your GitHub as a HTML.

    ```{r}
    #| message: false
    #| 
    library(tidyverse)
    library(robustbase) # star data
    library(boot) # bootstrapping
    library(correlation) # get different correlations
    library(permuco) # run permutation tests
    library(parameters) # SE
    library(data.table) # fread 
    library(infer) # sample_rep_n function
    library(palmerpenguins) # penguins dataset


    ```

## Robust Correlations

Use the `stars` data in `robustbase`. This data looks at the relationship between temperature at the surface of a star and the light intensity.

1.  

    ```{r}
    stars<-robustbase::starsCYG
    ```

    a\. Plot the data and describe the pattern seen. What is Pearson's *r*?

    b\. Re-run the correlation, but this time use the winsorized r (20%). Do this manually and then with the correlation::correlation function from `easystats`.

    c\. Compare the correlations.

## Bootstrapping and Permutations

2.  For the following data: \[8.453532, 10.025041, 11.495339, 9.367600, 8.333229, 9.788753, 10.883344, 10.543059, 9.869095, 10.799819\]

    a\. Bootstrap the mean (using the `boot` package) and plot the histogram with `ggplot2`

    b\. Bootstrap the median (using the `boot` package) and plot the histogram with `ggplot2`

    c\. For the mean bootstraps, plot the 95% confidence Intervals (Percentile and BCa) ) along with the mean. Use ggtext to mark the lines noting what they represent.

    d\. For the median bootstraps, plot the 95% Confidence Intervals (Percentile and BCa). Use ggtext to mark the lines noting what they represent.

3.  You want to test whether the following paired samples are significantly different from one another: pre = \[22,25,17,24,16,29,20,23,19,20\], post = \[18,21,16,22,19,24,17,21,23,18\]. Often researchers would run a paired sampled t-test, but you are concerned the data does not follow a normal distribution.

    a.  Calculate the paired differences, that is post - pre, which will result in a vector of paired differences (pdiff0 = post - pre)

    b\. Calculate the mean of the paired differences (Xpdiff0)

    d\. Bootstrap b) with replacement (pdiff1) and plot the histogram with `ggplot2`.

    e\. Calculate the 95% Confidence Intervals (BCa). What can you infer from this?

    f\. Plot bootstrap mean along with 95% CIs (with `ggplot2`). Use ggtext to note what the vertical lines represent.

    e\. Write up these results as they would appear in a journal

4.  Pepper Joe measured the length and heat of 85 chili peppers. He wants to know if smaller peppers are hotter than longer peppers.

    ```{r}
    #read data.table to read in
    chili<- read.delim("/Users/jasongeller/Documents/03-Robust_Methods/data/chillis.csv")
    ```

5.  Some species display sexual size dimorphism -- in which one sex is on average larger than the other. Such a pattern can tell us about the species' ecology and mating habits. Do penguins display this sex difference in size? Let's just look at a subset of the palmerpenguins data set, which we'll call `my_penguins`.

    ```{r}
    my_penguins <- penguins %>% 
      filter(species == "Adelie",
             !is.na(sex), 
             island == "Torgersen") 
    my_penguins
    ```

a\. Visualize body size by sex

b\. Calculate the original mean difference between sex

c\. Permute the group labels (10000x)

d\. Plot the Null-Hypothesis Distribution (NHD) for the Difference

e\. Compare the Observed Mean Difference to the NHD (is *p* \< .05?)

## Robust Linear Models

7.  Suppose we have the following data frame in R that contains information on the hours studied and exam score received by 20 students in some class:

```{r}
df <- data.frame(hours=c(1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4,
                         4, 5, 5, 5, 6, 6, 7, 7, 8),
                 score=c(67, 68, 74, 70, 71, 75, 80, 70, 84, 72,
                         88, 75, 95, 75, 99, 78, 99, 65, 96, 70))

```

a\. Use the [lm()](https://www.statology.org/lm-function-in-r/) function to fit a regression model in R that uses **hours** as the predictor variable and **score** as the response variable

b\. Interpret the results

c\. Check assumption and report (include plots)

d\. Rerun the lm you saved above, but with robust standard errors now

e\. What differences do you notice between the regular regression and the regression with robust SEs applied?
